# GPT

Step 1: Building a Baseline Model 1
1. Preprocessing using regex
2. Tokenization using encoding, decoding functions
3. Batching data into training and validation sets. Then, it is organized into batches for parallel processing

About Dataset: War and Peace by Leo Tolstoy, which contains over 3.2 million characters. 
Iâ€™ve inspected the first 200 characters of the dataset and extracted all the unique characters, resulting in a vocabulary size of 112
